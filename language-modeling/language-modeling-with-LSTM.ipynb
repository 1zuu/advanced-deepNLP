{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a72305-bd93-460d-8315-9b74f189f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = '<SOS>'.lower()\n",
    "END_TOKEN = '<EOS>'.lower()\n",
    "\n",
    "DATA_PATH = 'data/poetry.txt'\n",
    "\n",
    "CUTOFF = 0.8\n",
    "EPOCHES = 2000\n",
    "NUM_LAYERS = 1\n",
    "BATCH_SIZE = 128\n",
    "LATENT_DIM = 25\n",
    "EMBEDDING_DIM = 50\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc2f401f-6b85-433b-a47e-762a8704ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "import torchnlp.encoders.text as text_encoder\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66487d38-0c8d-4bcf-bb7b-dc6e9588aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    input_lines = []\n",
    "    target_lines = []\n",
    "    for line in open(DATA_PATH):\n",
    "        line = line.strip()\n",
    "        \n",
    "        input_line = '{} {}'.format(START_TOKEN, line)\n",
    "        target_line = '{} {}'.format(line, END_TOKEN)\n",
    "        \n",
    "        input_lines.append(input_line)\n",
    "        target_lines.append(target_line)\n",
    "        \n",
    "    return input_lines, target_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6704edc9-b7ce-4052-9a46-d4de64504ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_line(line, encoder):\n",
    "    return encoder.encode(line)\n",
    "\n",
    "def tokenize_lines(lines, encoder):\n",
    "    return [tokenize_line(line, encoder) for line in lines]\n",
    "\n",
    "def extract_max_length(all_seq_lengths):\n",
    "    return torch.max(all_seq_lengths).item()\n",
    "    \n",
    "def padding_line(tokens, MAX_LENGTH):\n",
    "    return text_encoder.pad_tensor(\n",
    "                                tokens, \n",
    "                                length = MAX_LENGTH\n",
    "                                )\n",
    "\n",
    "def padding_lines(all_tokens):\n",
    "    return text_encoder.stack_and_pad_tensors(\n",
    "                                            all_tokens\n",
    "                                            )\n",
    "\n",
    "def process_line(line, encoder, MAX_LENGTH):\n",
    "    tokens = tokenize_line(line, encoder)\n",
    "    padded = padding_line(tokens, MAX_LENGTH)\n",
    "    return padded\n",
    "\n",
    "def process_lines(lines, encoder):\n",
    "    all_tokens = tokenize_lines(lines, encoder)\n",
    "    all_padded = padding_lines(all_tokens)\n",
    "    return all_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faa2a602-30f0-4084-ad12-6dfc53ad26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "*** Make target Sequence OneHot ***\n",
    "\n",
    "    The Reason is that Sparse Categorical Cross Entropy won't work when Target is a Sequence.\n",
    "'''\n",
    "\n",
    "def make_one_hot_target_sequences(MAX_LENGTH, vocabulary, target_sequences):\n",
    "    onehot_target_sequences = torch.empty(\n",
    "                                    len(target_sequences),\n",
    "                                    MAX_LENGTH,\n",
    "                                    len(vocabulary),\n",
    "                                    dtype=torch.float32\n",
    "                                        )\n",
    "    \n",
    "    for idx, target_sequence in enumerate(target_sequences):\n",
    "        onehot_target_sequence = torch.nn.functional.one_hot(\n",
    "                                                    target_sequence, \n",
    "                                                    num_classes = len(vocabulary)\n",
    "                                                    )\n",
    "        onehot_target_sequences[idx, :, :] = onehot_target_sequence\n",
    "        \n",
    "    return onehot_target_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b44788aa-e828-4e00-918b-38394a300beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data():\n",
    "    input_lines, target_lines = load_data()\n",
    "    all_lines = input_lines + target_lines\n",
    "    encoder = text_encoder.StaticTokenizerEncoder(\n",
    "                                                all_lines, \n",
    "                                                tokenize = lambda s: s.split()\n",
    "                                                )\n",
    "\n",
    "    input_sequences, input_seq_lengths = process_lines(input_lines, encoder)\n",
    "    target_sequences, target_seq_lengths = process_lines(target_lines, encoder)\n",
    "    all_sequences, all_seq_lengths = process_lines(all_lines, encoder)\n",
    "\n",
    "    MAX_LENGTH = extract_max_length(all_seq_lengths)\n",
    "    vocabulary = encoder.vocab\n",
    "    \n",
    "    assert START_TOKEN in vocabulary, 'START_TOKEN NOT FOUND' \n",
    "    assert END_TOKEN in vocabulary, 'END_TOKEN NOT FOUND' \n",
    "    \n",
    "    target_sequences = make_one_hot_target_sequences(\n",
    "                                                    MAX_LENGTH,\n",
    "                                                    vocabulary, \n",
    "                                                    target_sequences\n",
    "                                                    )\n",
    "    \n",
    "    return input_sequences, input_seq_lengths, target_sequences, target_seq_lengths, encoder, MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4f1b79e-549a-439b-8393-d4cd6775ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageGenerator(torch.nn.Module):\n",
    "    def __init__(\n",
    "                self,\n",
    "                VOCAB_SIZE,\n",
    "                DEVICE\n",
    "                ):\n",
    "        super(LanguageGenerator,self).__init__()\n",
    "        \n",
    "        self.embedding_layer = torch.nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "        self.lstm_layer = torch.nn.LSTM(\n",
    "                                    input_size=EMBEDDING_DIM, \n",
    "                                    hidden_size=LATENT_DIM,\n",
    "                                    num_layers=NUM_LAYERS, \n",
    "                                    batch_first=True\n",
    "                                    ) \n",
    "\n",
    "        self.linear_layer = torch.nn.Linear(LATENT_DIM, VOCAB_SIZE)\n",
    "        \n",
    "        \n",
    "        self.DEVICE = DEVICE\n",
    "        self.VOCAB_SIZE = VOCAB_SIZE\n",
    "\n",
    "    def forward(self, x, memory_init):\n",
    "        x = x.long()\n",
    "        \n",
    "        x = self.embedding_layer(x)\n",
    "        x, _ = self.lstm_layer(x, memory_init) \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        output shape : (CHUNK_SIZE, MAX_LENGTH, LATENT_DIM)\n",
    "             --> Always return_sequences = True\n",
    "        \n",
    "        '''\n",
    "        x = self.linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ded47a63-1a93-4e2f-894f-2ed757a60988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelingPyTorch(object):\n",
    "    def __init__(self):\n",
    "        input_sequences, input_seq_lengths, target_sequences, target_seq_lengths, encoder, MAX_LENGTH = process_data()\n",
    "        \n",
    "        dataset = TensorDataset(\n",
    "                        input_sequences, \n",
    "                        target_sequences\n",
    "                                )\n",
    "        \n",
    "        train_data, valid_data = torch.utils.data.random_split(dataset, \n",
    "                                                              [int(len(input_sequences) * CUTOFF), len(input_sequences) - int(len(input_sequences) * CUTOFF)])\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "                            train_data, \n",
    "                            shuffle=False, \n",
    "                            drop_last=True,\n",
    "                            batch_size=BATCH_SIZE\n",
    "                                )\n",
    "    \n",
    "        valid_loader = DataLoader(\n",
    "                            valid_data, \n",
    "                            shuffle=False, \n",
    "                            drop_last=True,\n",
    "                            batch_size=BATCH_SIZE\n",
    "                                )\n",
    "        \n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.VOCAB_SIZE = len(encoder.vocab)\n",
    "        self.DEVICE = torch.device('cpu' if not torch.cuda.is_available() else 'cuda:0') \n",
    "        \n",
    "        h_init = torch.zeros(\n",
    "                        NUM_LAYERS, \n",
    "                        BATCH_SIZE, \n",
    "                        LATENT_DIM\n",
    "                        ).to(self.DEVICE) # Teacher Forcing Stratergy\n",
    "        \n",
    "        c_init = torch.zeros(\n",
    "                        NUM_LAYERS, \n",
    "                        BATCH_SIZE, \n",
    "                        LATENT_DIM\n",
    "                        ).to(self.DEVICE) # Teacher Forcing Stratergy\n",
    "        \n",
    "\n",
    "        h_init_eval = torch.zeros(\n",
    "                        NUM_LAYERS, \n",
    "                        1, \n",
    "                        LATENT_DIM\n",
    "                        ).to(self.DEVICE) # Predict for Individual Word\n",
    "        \n",
    "        c_init_eval = torch.zeros(\n",
    "                        NUM_LAYERS, \n",
    "                        1, \n",
    "                        LATENT_DIM\n",
    "                        ).to(self.DEVICE) # Predict for Individual Word\n",
    "        \n",
    "        self.memory_init = (h_init, c_init)\n",
    "        self.memory_init_eval = (h_init_eval, c_init_eval)\n",
    "            \n",
    "    def language_generator(self):        \n",
    "        model = LanguageGenerator(\n",
    "                                self.VOCAB_SIZE, \n",
    "                                self.DEVICE\n",
    "                                    )\n",
    "        \n",
    "        self.model = model.to(self.DEVICE)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(\n",
    "                                    self.model.parameters(),\n",
    "                                    lr = LEARNING_RATE\n",
    "                                        )\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "    def train_epoch(self):\n",
    "          \n",
    "        train_loss_epoch = 0\n",
    "        valid_loss_epoch = 0\n",
    "        self.model.train()\n",
    "        \n",
    "        for Xbatch, Ybatch in self.train_loader:\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            Xbatch = Xbatch.to(self.DEVICE)\n",
    "            Ybatch = Ybatch.to(self.DEVICE)\n",
    "        \n",
    "            CHUNK_SIZE = Xbatch.shape[0]\n",
    "            \n",
    "            Pbatch = self.model(Xbatch, self.memory_init).to(self.DEVICE)\n",
    "\n",
    "            train_loss = self.criterion(Pbatch, Ybatch)\n",
    "            train_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            train_loss_epoch += train_loss.item()\n",
    "            \n",
    "        train_loss_epoch = train_loss_epoch / len(self.train_loader)\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        for Xbatch, Ybatch in self.valid_loader:\n",
    "\n",
    "            Xbatch = Xbatch.to(self.DEVICE)\n",
    "            Ybatch = Ybatch.to(self.DEVICE)\n",
    "        \n",
    "            CHUNK_SIZE = Xbatch.shape[0]\n",
    "            \n",
    "            Pbatch = self.model(Xbatch,self.memory_init).to(self.DEVICE)\n",
    "\n",
    "            valid_loss = self.criterion(Pbatch, Ybatch)\n",
    "            \n",
    "            valid_loss_epoch += valid_loss.item()\n",
    "            \n",
    "        valid_loss_epoch = valid_loss_epoch / len(self.train_loader)\n",
    "        \n",
    "        return train_loss_epoch, valid_loss_epoch\n",
    "            \n",
    "    def train_loop(self):\n",
    "        train_loss, valid_loss = [], []\n",
    "        for epoch in range(EPOCHES):\n",
    "            train_loss_epoch, valid_loss_epoch = self.train_epoch()\n",
    "            \n",
    "            train_loss.append(train_loss_epoch)\n",
    "            valid_loss.append(valid_loss_epoch)\n",
    "            \n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print('EPOCH : {}, TRAIN LOSS : {}, VALID LOSS : {}'.format(epoch+1, train_loss_epoch, valid_loss_epoch))\n",
    "        \n",
    "        self.train_loss = train_loss\n",
    "        self.valid_loss = valid_loss\n",
    "        \n",
    "    def plot_cross_entropy(self):\n",
    "        plt.plot(self.train_loss, label='loss')\n",
    "        plt.plot(self.valid_loss, label='val_loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def train(self):\n",
    "        self.language_generator()\n",
    "        self.train_loop()\n",
    "        self.plot_cross_entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3d4e26f-c851-458e-b254-8250637fedc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 100, TRAIN LOSS : 0.0022117209284462864, VALID LOSS : 0.0016156330497728454\n",
      "EPOCH : 200, TRAIN LOSS : 0.0021997447410184476, VALID LOSS : 0.0017275071392456691\n",
      "EPOCH : 300, TRAIN LOSS : 0.002197232045647171, VALID LOSS : 0.0017997092670864528\n",
      "EPOCH : 400, TRAIN LOSS : 0.0021958982235648567, VALID LOSS : 0.0018522832542657852\n",
      "EPOCH : 500, TRAIN LOSS : 0.0021955354346169364, VALID LOSS : 0.001896600652900007\n",
      "EPOCH : 600, TRAIN LOSS : 0.0021954725056679714, VALID LOSS : 0.0019894404750731257\n",
      "EPOCH : 700, TRAIN LOSS : 0.002194951598842939, VALID LOSS : 0.0020342471284998786\n",
      "EPOCH : 800, TRAIN LOSS : 0.0021948395943683055, VALID LOSS : 0.0020619306920303237\n",
      "EPOCH : 900, TRAIN LOSS : 0.0022179053889380563, VALID LOSS : 0.0020912867039442062\n",
      "EPOCH : 1000, TRAIN LOSS : 0.002195059231275486, VALID LOSS : 0.0021128770377900866\n",
      "EPOCH : 1100, TRAIN LOSS : 0.002194773884386652, VALID LOSS : 0.002153797075152397\n",
      "EPOCH : 1200, TRAIN LOSS : 0.002194714137456483, VALID LOSS : 0.002180857066478994\n",
      "EPOCH : 1300, TRAIN LOSS : 0.002194653239308132, VALID LOSS : 0.002202224607268969\n",
      "EPOCH : 1400, TRAIN LOSS : 0.0021945707784551713, VALID LOSS : 0.0022289580148127344\n",
      "EPOCH : 1500, TRAIN LOSS : 0.002194529929612246, VALID LOSS : 0.0022505291013254058\n",
      "EPOCH : 1600, TRAIN LOSS : 0.0021945288818743494, VALID LOSS : 0.0022711755914820563\n",
      "EPOCH : 1700, TRAIN LOSS : 0.002195306342198617, VALID LOSS : 0.0023634020859996476\n",
      "EPOCH : 1800, TRAIN LOSS : 0.0021948134526610374, VALID LOSS : 0.0023854713266094527\n",
      "EPOCH : 1900, TRAIN LOSS : 0.002194686352999674, VALID LOSS : 0.002404167109893428\n",
      "EPOCH : 2000, TRAIN LOSS : 0.0021946559556656415, VALID LOSS : 0.0024195298966434267\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAo10lEQVR4nO3de3gc1X3/8fd3L7pY8g1jfAfLscExOAEiXEhj8gQaMAnBTQKxCSGGcmlTLiHJLykkLaU8+EkIbfilv0IoCSRASWzXQKsWN05SCISW2BaOwRhjI8xNwmD5fpF1//7+mFlptbuSVrKktT2f1/Pss7NnzuyemZXOd8+ZM2fM3RERkeiJFboAIiJSGAoAIiIRpQAgIhJRCgAiIhGlACAiElGJQhegL4499lifOnVqoYshInLEeOGFF7a7+9hc646oADB16lSqq6sLXQwRkSOGmb3V3Tp1AYmIRJQCgIhIRCkAiIhE1BF1DkBEoqelpYXa2loaGxsLXZTDWklJCZMnTyaZTOa9jQKAiBzWamtrGT58OFOnTsXMCl2cw5K7s2PHDmpra6moqMh7O3UBichhrbGxkTFjxqjy74GZMWbMmD63khQAROSwp8q/d/05RpEIAP/vv1/jmc31hS6GiMhhJRIB4N7fvs5zrykAiEj/lJeXF7oIgyISASBmoPveiIh0FZEAYLQrAIjIIXJ3vvnNb3LKKacwe/Zsli5dCsDWrVs5++yzOfXUUznllFP43e9+R1tbG1dccUVH3rvvvrvApc8WiWGgZtCuJoDIEe/v/mMDr7y7d0Dfc9bEEfztZ07OK+/jjz/OunXrePHFF9m+fTtnnHEGZ599Nj//+c85//zz+c53vkNbWxsNDQ2sW7eOuro6Xn75ZQB27949oOUeCNFoAcQM3ftYRA7Vc889x6WXXko8HmfcuHF8/OMfZ82aNZxxxhn89Kc/5bbbbmP9+vUMHz6cadOmsWXLFm644QZ++ctfMmLEiEIXP0skWgDqAhI5OuT7S32onX322Tz77LM8+eSTXHHFFXz961/ny1/+Mi+++CIrV67kvvvuY9myZTz44IOFLmoX0WgBqAtIRAbA3LlzWbp0KW1tbdTX1/Pss88yZ84c3nrrLcaNG8c111zD1Vdfzdq1a9m+fTvt7e18/vOf54477mDt2rWFLn6WSLQATC0AERkAn/3sZ3n++ef58Ic/jJnx/e9/n/Hjx/PQQw9x1113kUwmKS8v5+GHH6auro4rr7yS9vZ2AL773e8WuPTZ8goAZjYP+CEQB37i7t/LWF8MPAx8BNgBLHD3N8N1twBXAW3Aje6+Mkz/GnA14MB64Ep3H5TZnoJhoIoAItI/+/fvB4Ifk3fddRd33XVXl/WLFi1i0aJFWdsdjr/60/XaBWRmceAe4AJgFnCpmc3KyHYVsMvdpwN3A3eG284CFgInA/OAe80sbmaTgBuBSnc/hSCwLByYXcoWnANQABARSZfPOYA5QI27b3H3ZmAJMD8jz3zgoXB5OXCuBRNTzAeWuHuTu78B1ITvB0Hro9TMEsAw4N1D25Xu6SSwiEi2fALAJOCdtNe1YVrOPO7eCuwBxnS3rbvXAX8PvA1sBfa4+6/6swP50HUAIiLZCjIKyMxGE7QOKoCJQJmZfambvNeaWbWZVdfX928+n5iZpoIQEcmQTwCoA6akvZ4cpuXME3bpjCQ4Gdzdtn8CvOHu9e7eAjwOfDTXh7v7/e5e6e6VY8eOzaO42TQMVEQkWz4BYA0ww8wqzKyI4GRtVUaeKiB1Cvxi4CkPht1UAQvNrNjMKoAZwGqCrp8zzWxYeK7gXGDjoe9ObjoHICKSrddhoO7eambXAysJRus86O4bzOx2oNrdq4AHgEfMrAbYSTiiJ8y3DHgFaAWuc/c2YJWZLQfWhul/AO4f+N0L6ByAiEi2vK4DcPcVwIqMtFvTlhuBS7rZdjGwOEf63wJ/25fC9ldwDkABQEQGX3l5ecd1A5nefPNNLrzwwo4J4gotIlNBGOHFeCIiEorIVBDqAhI5KvzXzfDe+oF9z/Gz4YLvdbv65ptvZsqUKVx33XUA3HbbbSQSCZ5++ml27dpFS0sLd9xxB/PnZ14e1bPGxka+8pWvUF1dTSKR4Ac/+AGf+MQn2LBhA1deeSXNzc20t7fz2GOPMXHiRL7whS9QW1tLW1sbf/M3f8OCBQsOabchIgFAJ4FFpL8WLFjATTfd1BEAli1bxsqVK7nxxhsZMWIE27dv58wzz+Siiy7q043Z77nnHsyM9evX8+qrr3LeeeexefNm7rvvPr761a9y2WWX0dzcTFtbGytWrGDixIk8+eSTAOzZs2dA9i0aASCmuYBEjgo9/FIfLKeddhrbtm3j3Xffpb6+ntGjRzN+/Hi+9rWv8eyzzxKLxairq+P9999n/Pjxeb/vc889xw033ADAzJkzOeGEE9i8eTNnnXUWixcvpra2ls997nPMmDGD2bNn841vfIO/+qu/4sILL2Tu3LkDsm/ROQegACAi/XTJJZewfPlyli5dyoIFC3j00Uepr6/nhRdeYN26dYwbN47GxoGZy/KLX/wiVVVVlJaW8qlPfYqnnnqKE088kbVr1zJ79mz++q//mttvv31APisSLQBNBy0ih2LBggVcc801bN++nWeeeYZly5Zx3HHHkUwmefrpp3nrrbf6/J5z587l0Ucf5ZxzzmHz5s28/fbbnHTSSWzZsoVp06Zx44038vbbb/PSSy8xc+ZMjjnmGL70pS8xatQofvKTnwzIfkUiAOhKYBE5FCeffDL79u1j0qRJTJgwgcsuu4zPfOYzzJ49m8rKSmbOnNnn9/zLv/xLvvKVrzB79mwSiQQ/+9nPKC4uZtmyZTzyyCMkk0nGjx/Pt7/9bdasWcM3v/lNYrEYyWSSH/3oRwOyX3Yk9Y1XVlZ6dXV1n7f7/I/+l9JknH+5+o8GoVQiMpg2btzIBz/4wUIX44iQ61iZ2QvuXpkrf0TOAagFICKSKRJdQKaTwCIyhNavX8/ll1/eJa24uJhVq1YVqES5RSIABC2AQpdCRPrL3fs0xr7QZs+ezbp164b0M/vTnR+RLiDNBSRypCopKWHHjh36H+6Bu7Njxw5KSkr6tF1EWgAaBipypJo8eTK1tbX094ZQUVFSUsLkyZP7tE0kAoDmAhI5ciWTSSoqKgpdjKNSZLqA1AIQEekqIgFAcwGJiGSKSADQMFARkUyRCACmG8KIiGSJRADQlcAiItnyCgBmNs/MNplZjZndnGN9sZktDdevMrOpaetuCdM3mdn5YdpJZrYu7bHXzG4aqJ3KFFwHMFjvLiJyZOp1GKiZxYF7gE8CtcAaM6ty91fSsl0F7HL36Wa2ELgTWGBms4CFwMnAROA3Znaiu28CTk17/zrgiYHbra5iMbUAREQy5dMCmAPUuPsWd28GlgCZN7+cDzwULi8HzrXguu35wBJ3b3L3N4Ca8P3SnQu87u59n1A7T5oLSEQkWz4BYBLwTtrr2jAtZx53bwX2AGPy3HYh8Iv8i9x36gISEclW0JPAZlYEXAT8aw95rjWzajOr7u+l4DoJLCKSLZ8AUAdMSXs9OUzLmcfMEsBIYEce214ArHX397v7cHe/390r3b1y7NixeRQ3m64EFhHJlk8AWAPMMLOK8Bf7QqAqI08VsChcvhh4yoNLb6uAheEooQpgBrA6bbtLGeTuH9BcQCIiufQ6CsjdW83semAlEAcedPcNZnY7UO3uVcADwCNmVgPsJAgShPmWAa8ArcB17t4GYGZlBCOL/nwQ9qsLnQMQEcmW12yg7r4CWJGRdmvaciNwSTfbLgYW50g/QHCieNDpHICISLaIXAmsYaAiIpkiEQBMJ4FFRLJEIgBoOmgRkWwRCQBqAYiIZIpIANBJYBGRTJEIAMH9ABQARETSRSIA6DoAEZFsEQkA6gISEckUjQAQ00lgEZFMkQgAmgtIRCRbJAKAzgGIiGSLSABQC0BEJFNEAoDmAhIRyRSJAKC5gEREskUiAMQseNZ8QCIinSISAIII0KZmgIhIh0gEgHjYBGhTC0BEpEMkAkCqBdDeXuCCiIgcRiIRAOLhXmokkIhIp7wCgJnNM7NNZlZjZjfnWF9sZkvD9avMbGraulvC9E1mdn5a+igzW25mr5rZRjM7a0D2KIeOcwAKACIiHXoNAGYWB+4BLgBmAZea2ayMbFcBu9x9OnA3cGe47SxgIXAyMA+4N3w/gB8Cv3T3mcCHgY2Hvju5dXYBKQCIiKTk0wKYA9S4+xZ3bwaWAPMz8swHHgqXlwPnmpmF6Uvcvcnd3wBqgDlmNhI4G3gAwN2b3X33Ie9NNzpOAisAiIh0yCcATALeSXtdG6blzOPurcAeYEwP21YA9cBPzewPZvYTMyvr1x7kIaZRQCIiWQp1EjgBnA78yN1PAw4AWecWAMzsWjOrNrPq+vr6fn1YPOwCUv0vItIpnwBQB0xJez05TMuZx8wSwEhgRw/b1gK17r4qTF9OEBCyuPv97l7p7pVjx47No7jZUlcCqwtIRKRTPgFgDTDDzCrMrIjgpG5VRp4qYFG4fDHwlAfzLlQBC8NRQhXADGC1u78HvGNmJ4XbnAu8coj70q2YzgGIiGRJ9JbB3VvN7HpgJRAHHnT3DWZ2O1Dt7lUEJ3MfMbMaYCdBkCDMt4ygcm8FrnP3tvCtbwAeDYPKFuDKAd63DqkuIF0HICLSqdcAAODuK4AVGWm3pi03Apd0s+1iYHGO9HVAZR/K2m+pUUBqAIiIdIrElcCmcwAiIlkiEQA6WwAKACIiKdEIAJoOWkQkSyQCQEwtABGRLNEIAJoOWkQkSyQCQGo6aE0FISLSKRIBQLeEFBHJFokAoFFAIiLZohEAdD8AEZEskQgApjuCiYhkiUQA6OgC0iggEZEOEQkAwbNaACIinSIRAGKaDVREJEu0AoBOAouIdIhEANBN4UVEskUiAKgLSEQkWyQCQGcLoMAFERE5jEQiAKRuCq8WgIhIp2gEAE0FISKSJa8AYGbzzGyTmdWY2c051heb2dJw/Sozm5q27pYwfZOZnZ+W/qaZrTezdWZWPSB70w3dEEZEJFuvN4U3szhwD/BJoBZYY2ZV7v5KWrargF3uPt3MFgJ3AgvMbBawEDgZmAj8xsxOdPe2cLtPuPv2AdyfnDQKSEQkWz4tgDlAjbtvcfdmYAkwPyPPfOChcHk5cK4FE/DMB5a4e5O7vwHUhO83pFJdQOoBEhHplE8AmAS8k/a6NkzLmcfdW4E9wJhetnXgV2b2gpld2/ei5y91ElhTQYiIdOq1C2gQfczd68zsOODXZvaquz+bmSkMDtcCHH/88f36IJ0DEBHJlk8LoA6YkvZ6cpiWM4+ZJYCRwI6etnX31PM24Am66Rpy9/vdvdLdK8eOHZtHcbNpFJCISLZ8AsAaYIaZVZhZEcFJ3aqMPFXAonD5YuApd/cwfWE4SqgCmAGsNrMyMxsOYGZlwHnAy4e+O7nphjAiItl67QJy91Yzux5YCcSBB919g5ndDlS7exXwAPCImdUAOwmCBGG+ZcArQCtwnbu3mdk44InwRi0J4Ofu/stB2D8g7Z7Aqv9FRDrkdQ7A3VcAKzLSbk1bbgQu6WbbxcDijLQtwIf7Wtj+ioXtHLUAREQ6ReJK4EQYAVoVAEREOkQiAHReCKbZ4EREUiIRAJLxIAC06CSAiEiHSAQAMyMeM10HICKSJhIBAIJuoBZ1AYmIdIhMAEjGjFZ1AYmIdIhMAEjEY7TqlmAiIh2iEwBipmGgIiJpohMA4uoCEhFJF50AEIvpJLCISJrIBIBkXMNARUTSRSYAxDUKSESki8gEgGQ8RotGAYmIdIhMAEioC0hEpIvIBIB4LEaLAoCISIfIBIDgSmB1AYmIpEQmAOg6ABGRrqITAGIxWnUdgIhIh+gEgLimghARSZdXADCzeWa2ycxqzOzmHOuLzWxpuH6VmU1NW3dLmL7JzM7P2C5uZn8ws/885D3pRSIW0w1hRETS9BoAzCwO3ANcAMwCLjWzWRnZrgJ2uft04G7gznDbWcBC4GRgHnBv+H4pXwU2HupO5CMRM90SUkQkTT4tgDlAjbtvcfdmYAkwPyPPfOChcHk5cK6ZWZi+xN2b3P0NoCZ8P8xsMvBp4CeHvhu900lgEZGu8gkAk4B30l7Xhmk587h7K7AHGNPLtv8X+BbQ489yM7vWzKrNrLq+vj6P4uaWjGsyOBGRdAU5CWxmFwLb3P2F3vK6+/3uXunulWPHju33ZyZiRptaACIiHfIJAHXAlLTXk8O0nHnMLAGMBHb0sO0fAxeZ2ZsEXUrnmNm/9KP8eUvETVcCi4ikyScArAFmmFmFmRURnNStyshTBSwKly8GnnJ3D9MXhqOEKoAZwGp3v8XdJ7v71PD9nnL3Lw3A/nQrEdMtIUVE0iV6y+DurWZ2PbASiAMPuvsGM7sdqHb3KuAB4BEzqwF2ElTqhPmWAa8ArcB17t42SPvSI50EFhHpqtcAAODuK4AVGWm3pi03Apd0s+1iYHEP7/1b4Lf5lONQ6J7AIiJdRehKYE0FISKSLjIBIBkzWtqc4NSEiIhEJgDEY8GuqhdIRCQQmQCQiBuAbgspIhKKTABIhgFAJ4JFRAKRCQCJsAuopVUtABERiFAAKE4Gu9qsLiARESBCAaAkEcxC3dSiACAiAhEKAKkWQGNrQS5EFhE57EQnAKgFICLSRWQCQEnYAmhSC0BEBIhQAEi1ABrVAhARASIVANQCEBFJF5kAUJIMzwHoOgARESBCASDVAmhsUQtARASiFAA6TgKrBSAiAhEKAJ0XgqkFICICEQoAnReCqQUgIgJRCgC6EExEpIu8AoCZzTOzTWZWY2Y351hfbGZLw/WrzGxq2rpbwvRNZnZ+mFZiZqvN7EUz22Bmfzdge9SNeMxIxo2D6gISEQHyCABmFgfuAS4AZgGXmtmsjGxXAbvcfTpwN3BnuO0sYCFwMjAPuDd8vybgHHf/MHAqMM/MzhyQPepBeXGC/U0tg/0xIiJHhHxaAHOAGnff4u7NwBJgfkae+cBD4fJy4FwzszB9ibs3ufsbQA0wxwP7w/zJ8DHod2oZXpJkf2PrYH+MiMgRIZ8AMAl4J+11bZiWM4+7twJ7gDE9bWtmcTNbB2wDfu3uq3J9uJlda2bVZlZdX1+fR3G7F7QAFABERKCAJ4Hdvc3dTwUmA3PM7JRu8t3v7pXuXjl27NhD+szhJQn2qgUgIgLkFwDqgClpryeHaTnzmFkCGAnsyGdbd98NPE1wjmBQDS9JqAtIRCSUTwBYA8wwswozKyI4qVuVkacKWBQuXww85e4epi8MRwlVADOA1WY21sxGAZhZKfBJ4NVD3pteDC9Jsk8ngUVEAEj0lsHdW83semAlEAcedPcNZnY7UO3uVcADwCNmVgPsJAgShPmWAa8ArcB17t5mZhOAh8IRQTFgmbv/52DsYLryYrUARERSeg0AAO6+AliRkXZr2nIjcEk32y4GFmekvQSc1tfCHqrhJQn2Nbbi7gSDlEREoisyVwIDHFNWRGu7s/egWgEiIpEKAMeWFwOw/UBTgUsiIlJ4kQoAY8qLANixv7nAJRERKbxoBYCyoAWwY79aACIikQoAx4YtgO0KACIi0QoAY8qLScaNut2NhS6KiEjBRSoAxGPGlNHDeHvngUIXRUSk4CIVAACmHDOMt3c2FLoYIiIFF7kAMG1sGTXb9tPSpjuDiUi0RS4AnH78aBpb2tm4dW+hiyIi0rv2Nmja33u+fshrKoijSeXU0QCsfmMnH5o8qrCFEZHDnzu0NUPzAWjeDy0Hob0VmhugtRHaW6ClEVoPdj63NgX5Wpu6ed0MbU3hc7jc3BC+d9r7eXvwGD4BvjHw82VGLgBMGFnKByeMoOrFd7l67rRCF0dEBtLut6F4OJSOhsY9sOtNOLg7qKib94eVeEPa8gFoOdC5nOvRciCo8PvFIFkKiWJIlKQ9iiBeHKQnRwTLRcOCvLFk5zaxRPAYNmYAD1KnyAUAgEvnTOHWf9/A/9Rs54+nH1vo4ojIANj/6lOUL/ls8CJRGvyC7kksAUVlUFQePpdBsgzKx4Wvh2WvKyoLK+lw20RxWGGXQHJYZwWfLAnKEE/CYTzxZCQDwBcqp/Dj323hW8tfYtlfnMWkUaWFLpIU2J6GFja8u4eP6gfBkalpf2flDzDpIzD9HBgzPfj1nCwNKvPksM5KP1FUuPIeJiIZAEqSce754ul88cer+PQ//o7rPzGdT39oAhNGDm4g2LrnIP/8zBa+eu4MRpcd/n98Ta1tfH3piyz66FTmVBxT6OIMqm//23qefGkrv/n6x5l+XHmhi3Pkcw+6XZr2Bf3aLWF/dmtj0DXT2ghtLXBwZ1rfeBO0NITPYVdNe0uwvmlfkN7RLdMA3hbkMQv60YHn22bxz9N+yM+unFPgA3BkiGQAAPjQ5FFUXf/HfPuJ9dzx5EbueHIj048rZ+b44VQcW8aoYUWMKk0yaliSUcOKGFmaoDgRpyQZpzgZoygePGKx/Jt3313xKlUvvktrezt3/OnsQdy7gfG/r+/gyfVbeXL9VjbdMY/iRLzQRRo0q7bsBGD5C7XcfMHMApdmCLW3B5Vp6gRn096gsk1V4M37gxEorY1wcFdYGe8NKvGm/UEl3N4a9rM3dX2f/vSbx4uCrpNkadAFk+peKR4Bw8pg1JTwl3wpWDz4Ne/tUDKSJzY1cmvNDEre3cuBplbKiiNbveXNgjs3HhkqKyu9urp6wN/3tff38dSr21j9xk42b9tH7a6D5HtY4jEjbkYsRvhsxGNGImbEzDAL/pfavescROXFiSCYJA5tJG5P319vu9DbPu5saKa5NbheYkxZEWPKi0jEYsRiYAT7ZgBmWPAUPluXsqU+JvV5HR+bY72HrzryZmyTub+d673H/J2fmb2+pc2p2x30FydixrSxZRQlYsRjMVLhPdWN2/naurzumqdr5oHoAU54M6XtDQzzBkq9gdL2Bkr9IMXeSKk3UOTNwYMmir2JIm8i4S0kvYUy309JeyNF3kSc1nDb4FHifZsXq4UkB2PDOGDlHIyV0k6cNuI0xMpotiKarJiDNowGG8bB8NEUpoPRRDEHYuU0WxGtxNkfG85BSmixJC0kabPgR0b619zlG8/8PtPyrq/bA0DM4JiyYsaNKCaR/gMtrS8+1/eWnZ5P/twbd5e/v0aWJvnnyyv7ta2ZveDuOTdWiARmjBvOjHHD+fOPfwCAtnZnX2MLuxta2H2whd0Nzew52EJTSzuNrW00t7bT1NpOS1vwaGuHdnfa2oNH+nKKGSTjMa6ZO43fbtrG6/UHaGpt76hge9LbH1BPq3vftvsMibhx+VknsHHrXp7ZVN+xz+0eVJxOqtJOq2jDSjz1vpmfn1lx5qpYM9eR8V7Z22as76UizlWGC0dM4Kq5Fdz79Ou8t6eR5rZ2WttT+9Rz0OmSlhmQ2p1Sb2Bk+27K2vd3VLwdlXlaZTwsbTmVnsqTJP97WTeTpNmKabUkrSTYHyun0UpptGJarZz34hODyjlWGqaX0GQlHLRSGmJlNNow2jGarZhGK6ExVkoLReyLDcctrRXo5Kz0clWQXdJyrE9YdmXUWwWcWVmfO/M4Lj/rBBpb2nhy/Xs0NLXS5l1/GKSK3bHcza+grvmzv+e882S87q/B+p2uFoCIO/xiYdB9cUUvt6Z2D7o/9m+D/e/DgW2wvx4admQ8dnYut/dSeceLg6GLHY8RGa+7SS8qD7pJiod3dpskSiAWues7pQeH3AIws3nADwluCv8Td/9exvpi4GHgI8AOYIG7vxmuuwW4CmgDbnT3lWY2Jcw/jiBI3u/uP+zHvokE3IM+6KZ9Qf9z8/5weX948U5D8Lpxb+e4733vBePEd24J+rgBDmwP+rrfWw9762Dvu8Hznrqgwt//fscJxy4sBqXHBCNOho2BYypgcmX4+hgoGwslo3JU6OXBUEKRAug1AJhZHLgH+CRQC6wxsyp3fyUt21XALnefbmYLgTuBBWY2C1gInAxMBH5jZicCrcA33H2tmQ0HXjCzX2e8p0RBa1NYSYeVddO+zso7dQKycQ80bA8q58Y9naNAmg90jjDpy8U6iXDM9vDxMOqEIG1b+Kd31we65k2WwchJwZWYUz8G5cdB2XHBWPHy8LlsLJSOgtjRe5Jcjk75tADmADXuvgXAzJYA84H0yno+cFu4vBz4Jws68OYDS9y9CXjDzGqAOe7+PLAVwN33mdlGYFLGe8qRyD34Bb2nNvjlfKA+7C5JdZnUBxV5w46gMu+teySldDQMOzaoaIvKg8o3GV45mXrO7B4pHh78wk6NGkl1oeSqqBv3wvemBJX7Od+BiafD6BOCbQ7jC3lEDkU+AWAS8E7a61rgj7rL4+6tZrYHGBOm/z5j20npG5rZVOA0YFWuDzeza4FrAY4//vg8iiuDrqURtm+C+s2w553gsTvtuSXH/RaKR4a/mI+DsScFXSMlI8MKenjXyjrVNZKqxIvKIT7I4xVKRsBtewb3M0QOMwUdBWRm5cBjwE3unnN6Tne/H7gfgpPAQ1g8Sdn9DmxaAW8/D++/AjtqgvHfKaWjYdTxwVWXHzgHRk4Ju00mwvCwiySpq61FDjf5BIA6YEra68lhWq48tWaWAEYSnAzudlszSxJU/o+6++P9Kr0cOvfgpGnDDjiQNopl+2ZY80DQN58y8ngYPxtmXQTHzYLjPhhU9sW6clbkSJRPAFgDzDCzCoLKeyHwxYw8VcAi4HngYuApd3czqwJ+bmY/IDgJPANYHZ4feADY6O4/GJhdESC4srNxd9Dfvm9rMBwx1efe3aO3k6fHfxQ+/Q8wbtaQ7IKIDI1eA0DYp389sJJgGOiD7r7BzG4Hqt29iqAyfyQ8ybuTIEgQ5ltGcHK3FbjO3dvM7GPA5cB6M1sXftS33X3FAO/f0aOtJRi2uG9r2vDEcIji7reDsegtDcHcKp7r4jILhiN2DFOcljZM8djO9NSwxURJMMrm4C6YcsaQ766IDD5dCHY4SI2c2fUm7H4Ldr3VWbmnKvr975M1uUOiFEZMDIYzdlTux0LZsUG/+4iJnZW7himKRFK0p4Jwh43/AaOnwoQPFbYs9ZvgmA8Efe41v4E3n4P3XoKdbwTdNumKRwYV+IiJQdfLiEnh6/B5+ITg5KuGKIpIPx39AcAMnvhzqPyzwQ8A7sE49x018N7LsG1D8Kt+11vBEMnMvvbikTDxVDjl88GVo6MrgkA16vhgWKKIyCA6+gMABJfgZ/7CHgh734XaaqhdA1vXwbZXg7lhUkpHB33tE0+DD14IW54JfvGXjIIvPR5U/uqWEZECiUgAGBnMV34omvZB3VrY+iLUVQcV/95wNGy8CMadAtP/JGhljJkO404Oumkyu2h2vw0jJmvCLhEpuGgEgNJRwbQDfbX7bXj58bC//ned6aNOgOPPCkbRTD4jGBuf74Reo3Q1s4gcHqIRAEpGdv5a782+92DDv8HLj0Ht6iBt/IfgtMth0ukw88JgOgMRkSNcRALAqM7ZHnNpb4NX/xNW/zgYmYMHXTrn3gonfy44QSsicpSJSAAYCQdzdAG5BxX/r28N5oQfPRU+/q2g0j8uQveFFZFIikYAKB0FTXuCX/qpUTc7XoeqG+Ct/4GxM+Hin8Ks+RqVIyKREY0AUDIyeG7aGwzN3LwSHrs6mDLhU38PH7ly8KcbFhE5zESj1isZFTwf3AVv/A6W/xkceyIsfFT9+yISWdEIAGPC2/yt/jGsvj+429Nl/xp0DYmIRFQ0rkYaPzu4y9Tv7w3m0rl0iSp/EYm8aLQAisqCqRdeWgJzvwFlYwpdIhGRgotGAIBgTnvNay8i0iEaXUAiIpJFAUBEJKIUAEREIkoBQEQkovIKAGY2z8w2mVmNmd2cY32xmS0N168ys6lp624J0zeZ2flp6Q+a2TYze3lA9kRERPqk1wBgZnHgHuACYBZwqZnNysh2FbDL3acDdwN3htvOAhYCJwPzgHvD9wP4WZgmIiIFkE8LYA5Q4+5b3L0ZWALMz8gzH3goXF4OnGtmFqYvcfcmd38DqAnfD3d/Ftg5APsgIiL9kE8AmAS8k/a6NkzLmcfdW4E9wJg8t+2RmV1rZtVmVl1fX9+XTUVEpAeH/YVg7n4/cD+AmdWb2Vv9fKtjge0DVrCBo3L1jcrVNypX3xyN5TqhuxX5BIA6YEra68lhWq48tWaWAEYCO/LcNm/uPra/25pZtbtX9nf7waJy9Y3K1TcqV99ErVz5dAGtAWaYWYWZFRGc1K3KyFMFLAqXLwaecncP0xeGo4QqgBnA6oEpuoiIHIpeA0DYp389sBLYCCxz9w1mdruZXRRmewAYY2Y1wNeBm8NtNwDLgFeAXwLXuXsbgJn9AngeOMnMas3sqoHdNRER6Ule5wDcfQWwIiPt1rTlRuCSbrZdDCzOkX5pn0p66O4f4s/Ll8rVNypX36hcfROpclnQUyMiIlGjqSBERCJKAUBEJKKO+gDQ2zxGg/zZU8zsaTN7xcw2mNlXw/TbzKzOzNaFj0+lbZNz7qRBKNubZrY+/PzqMO0YM/u1mb0WPo8O083M/jEs10tmdvoglemktGOyzsz2mtlNhTpeuear6s8xMrNFYf7XzGxRrs8agHLdZWavhp/9hJmNCtOnmtnBtGN3X9o2Hwn/BmrCstsglKvP391A/892U66laWV608zWhelDcrx6qBuG9u/L3Y/aBxAHXgemAUXAi8CsIfz8CcDp4fJwYDPBfEq3Af8nR/5ZYRmLgYqw7PFBKtubwLEZad8Hbg6XbwbuDJc/BfwXYMCZwKoh+u7eI7iIpSDHCzgbOB14ub/HCDgG2BI+jw6XRw9Cuc4DEuHynWnlmpqeL+N9VodltbDsFwxCufr03Q3G/2yucmWs/wfg1qE8Xj3UDUP693W0twDymcdo0Lj7VndfGy7vIxhG29NUGN3OnTRE0ud0egj407T0hz3we2CUmU0Y5LKcC7zu7j1d+T2ox8tzz1fV12N0PvBrd9/p7ruAX3OIkyDmKpe7/8qDIdsAvye46LJbYdlGuPvvPahJHk7blwErVw+6++4G/H+2p3KFv+K/APyip/cY6OPVQ90wpH9fR3sAOOS5iAaKBVNknwasCpOuD5tyD6aaeQxteR34lZm9YGbXhmnj3H1ruPweMK4A5UpZSNd/ykIfr5S+HqNClPHPCH4tplSY2R/M7BkzmxumTQrLMhTl6st3N9THay7wvru/lpY2pMcro24Y0r+voz0AHBbMrBx4DLjJ3fcCPwI+AJwKbCVogg61j7n76QTTfF9nZmenrwx/5RRkjLAFV5xfBPxrmHQ4HK8shTxG3TGz7wCtwKNh0lbgeHc/jeAizZ+b2YghLNJh+d2luZSuPzSG9HjlqBs6DMXf19EeAAZ0LqL+MLMkwRf8qLs/DuDu77t7m7u3Az+ms9tiyMrr7nXh8zbgibAM76e6dsLnbUNdrtAFwFp3fz8sY8GPV5q+HqMhK6OZXQFcCFwWVh6EXSw7wuUXCPrXTwzLkN5NNCjl6sd3N5THKwF8DliaVt4hO1656gaG+O/raA8A+cxjNGjC/sUHgI3u/oO09PT+888CqdEJQzJ3kpmVmdnw1DLBCcSX6Tqn0yLg39PK9eVwJMKZwJ60Zupg6PKrrNDHK0Nfj9FK4DwzGx12f5wXpg0oM5sHfAu4yN0b0tLHWngTJjObRnCMtoRl22tmZ4Z/p19O25eBLFdfv7uh/J/9E+BVd+/o2hmq49Vd3cBQ/3319yz2kfIgOHu+mSCSf2eIP/tjBE24l4B14eNTwCPA+jC9CpiQts13wrJu4hBHZfRQrmkEoyteBDakjgvBPRz+G3gN+A1wTJhuBHeFez0sd+UgHrMygplkR6alFeR4EQShrUALQd/qVf05RgR98jXh48pBKlcNQV9w6u/svjDv58PveB2wFvhM2vtUElTIrwP/RDgzwACXq8/f3UD/z+YqV5j+M+AvMvIOyfGi+7phSP++NBWEiEhEHe1dQCIi0g0FABGRiFIAEBGJKAUAEZGIUgAQEYkoBQARkYhSABARiaj/D0hiWAlrHQe0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LMP = LanguageModelingPyTorch()\n",
    "LMP.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d20a241",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'memory_init'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\my-projects\\learning\\Natural-Language-Processing-with-PyTorch\\language-modeling-with-LSTM.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Projects/my-projects/learning/Natural-Language-Processing-with-PyTorch/language-modeling-with-LSTM.ipynb#ch0000015?line=0'>1</a>\u001b[0m summary(LMP\u001b[39m.\u001b[39;49mmodel, (\u001b[39m12\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\Legion\\.conda\\envs\\torch111\\lib\\site-packages\\torchsummary\\torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     68\u001b[0m model\u001b[39m.\u001b[39mapply(register_hook)\n\u001b[0;32m     70\u001b[0m \u001b[39m# make a forward pass\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m# print(x.shape)\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m model(\u001b[39m*\u001b[39;49mx)\n\u001b[0;32m     74\u001b[0m \u001b[39m# remove these hooks\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m hooks:\n",
      "File \u001b[1;32mc:\\Users\\Legion\\.conda\\envs\\torch111\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'memory_init'"
     ]
    }
   ],
   "source": [
    "summary(LMP.model, (12, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08a85bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageGenerator(\n",
       "  (embedding_layer): Embedding(3291, 50)\n",
       "  (lstm_layer): LSTM(50, 25, batch_first=True)\n",
       "  (linear_layer): Linear(in_features=25, out_features=3291, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LMP.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e467b591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 12, 3291])\n"
     ]
    }
   ],
   "source": [
    "for Xbatch, Ybatch in LMP.train_loader:\n",
    "    Xbatch = Xbatch.to('cuda:0')\n",
    "    Ybatch = Ybatch.to('cuda:0')\n",
    "\n",
    "    Pbatch = LMP.model(Xbatch, LMP.memory_init).to('cuda:0')\n",
    "    print(Pbatch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e239c99-4203-4386-847c-ab91028372c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LanguageGenerator(\n",
      "  (embedding_layer): Embedding(3291, 50)\n",
      "  (lstm_layer): LSTM(50, 25, batch_first=True)\n",
      "  (linear_layer): Linear(in_features=25, out_features=3291, bias=True)\n",
      ")\n",
      "Embedding(3291, 50)\n",
      "LSTM(50, 25, batch_first=True)\n",
      "Linear(in_features=25, out_features=3291, bias=True)\n"
     ]
    }
   ],
   "source": [
    "class LanguageGeneratorInference(torch.nn.Module):\n",
    "    def __init__(\n",
    "                self,\n",
    "                VOCAB_SIZE,\n",
    "                DEVICE,\n",
    "                model\n",
    "                ):\n",
    "        super(LanguageGeneratorInference,self).__init__()\n",
    "        \n",
    "        self.embedding_layer = torch.nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "        self.lstm_layer = torch.nn.LSTM(\n",
    "                                    input_size=EMBEDDING_DIM, \n",
    "                                    hidden_size=LATENT_DIM,\n",
    "                                    num_layers=NUM_LAYERS, \n",
    "                                    batch_first=True\n",
    "                                    ) \n",
    "\n",
    "        self.linear_layer = torch.nn.Linear(LATENT_DIM, VOCAB_SIZE)\n",
    "        \n",
    "        \n",
    "        self.DEVICE = DEVICE\n",
    "        self.VOCAB_SIZE = VOCAB_SIZE\n",
    "\n",
    "    def forward(self, x, memory_init):\n",
    "        x = x.long()\n",
    "        \n",
    "        x = self.embedding_layer(x)\n",
    "        x, _ = self.lstm_layer(x, memory_init) \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        output shape : (CHUNK_SIZE, MAX_LENGTH, LATENT_DIM)\n",
    "             --> Always return_sequences = True\n",
    "        \n",
    "        '''\n",
    "        x = self.linear_layer(x)\n",
    "        return x\n",
    "    \n",
    "for layer in LMP.model.modules():\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1035d26-9e55-4ee3-bbd2-8dc17c449154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbb251-3878-49f8-adb8-5140c55852e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch111')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "38d61779fb8a2d479ca2bc1a752fe475f56efe678dc670cf5ac86029018bbcc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
